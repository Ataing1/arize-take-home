# Attention Mechanisms

Attention mechanisms allow neural networks to focus on relevant parts of the input when producing output.

## Types of Attention:
1. Self-Attention
2. Multi-Head Attention
3. Cross-Attention

## Applications:
- Natural Language Processing
- Computer Vision
- Speech Recognition
